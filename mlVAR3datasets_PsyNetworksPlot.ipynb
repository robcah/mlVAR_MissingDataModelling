{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35125341-5751-49fe-b13b-855189df69a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_49288\\1329859419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f170fd0a-dc8d-48a0-9f67-d12265ecbafc",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "root_folder = r'.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02dd395e-b33a-4bb1-a02a-59d1e270e355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'between':                    n0                 n1 similarity\n",
       " 0          depression       hopelessness      0.425\n",
       " 1              voices       hopelessness      0.014\n",
       " 2              voices         depression     -0.027\n",
       " 3             visions       hopelessness      0.015\n",
       " 4             visions         depression      0.117\n",
       " 5             visions             voices      0.421\n",
       " 6             anxiety       hopelessness     -0.175\n",
       " 7             anxiety         depression      0.741\n",
       " 8             anxiety             voices      0.038\n",
       " 9             anxiety            visions     -0.005\n",
       " 10           paranoia       hopelessness     -0.255\n",
       " 11           paranoia         depression      0.448\n",
       " 12           paranoia             voices      0.201\n",
       " 13           paranoia            visions     -0.247\n",
       " 14           paranoia            anxiety      0.019\n",
       " 15          delusions       hopelessness      0.118\n",
       " 16          delusions         depression     -0.323\n",
       " 17          delusions             voices     -0.046\n",
       " 18          delusions            visions      0.551\n",
       " 19          delusions            anxiety      0.099\n",
       " 20          delusions           paranoia      0.725\n",
       " 21  missed_encounters       hopelessness      -0.16\n",
       " 22  missed_encounters         depression      0.095\n",
       " 23  missed_encounters             voices      0.028\n",
       " 24  missed_encounters            visions      0.104\n",
       " 25  missed_encounters            anxiety     -0.161\n",
       " 26  missed_encounters           paranoia      0.117\n",
       " 27  missed_encounters          delusions     -0.113\n",
       " 28      disengagement       hopelessness      0.134\n",
       " 29      disengagement         depression     -0.023\n",
       " 30      disengagement             voices     -0.028\n",
       " 31      disengagement            visions     -0.101\n",
       " 32      disengagement            anxiety      0.099\n",
       " 33      disengagement           paranoia     -0.149\n",
       " 34      disengagement          delusions      0.133\n",
       " 35      disengagement  missed_encounters      0.971,\n",
       " 'contemporaneous':                    n0                 n1 similarity\n",
       " 0          depression       hopelessness       0.15\n",
       " 1              voices       hopelessness     -0.002\n",
       " 2              voices         depression      0.111\n",
       " 3             visions       hopelessness     -0.013\n",
       " 4             visions         depression      0.008\n",
       " 5             visions             voices      0.228\n",
       " 6             anxiety       hopelessness      0.029\n",
       " 7             anxiety         depression      0.271\n",
       " 8             anxiety             voices      0.054\n",
       " 9             anxiety            visions        0.1\n",
       " 10           paranoia       hopelessness      0.045\n",
       " 11           paranoia         depression      0.107\n",
       " 12           paranoia             voices       0.02\n",
       " 13           paranoia            visions      0.022\n",
       " 14           paranoia            anxiety      0.089\n",
       " 15          delusions       hopelessness      0.008\n",
       " 16          delusions         depression      0.104\n",
       " 17          delusions             voices      0.076\n",
       " 18          delusions            visions      0.031\n",
       " 19          delusions            anxiety      0.117\n",
       " 20          delusions           paranoia      0.198\n",
       " 21  missed_encounters       hopelessness      0.005\n",
       " 22  missed_encounters         depression     -0.002\n",
       " 23  missed_encounters             voices      0.022\n",
       " 24  missed_encounters            visions      0.003\n",
       " 25  missed_encounters            anxiety     -0.006\n",
       " 26  missed_encounters           paranoia       0.02\n",
       " 27  missed_encounters          delusions      0.005\n",
       " 28      disengagement       hopelessness     -0.004\n",
       " 29      disengagement         depression      0.009\n",
       " 30      disengagement             voices      0.003\n",
       " 31      disengagement            visions     -0.012\n",
       " 32      disengagement            anxiety      0.001\n",
       " 33      disengagement           paranoia     -0.004\n",
       " 34      disengagement          delusions      0.006\n",
       " 35      disengagement  missed_encounters      0.161,\n",
       " 'temporal':                n0                 n1 similarity\n",
       " 0    hopelessness       hopelessness      0.473\n",
       " 1    hopelessness         depression      0.015\n",
       " 2    hopelessness             voices     -0.007\n",
       " 3    hopelessness            visions      0.002\n",
       " 4    hopelessness            anxiety      0.031\n",
       " ..            ...                ...        ...\n",
       " 76  disengagement            anxiety     -0.004\n",
       " 77  disengagement           paranoia     -0.009\n",
       " 78  disengagement          delusions     -0.011\n",
       " 79  disengagement  missed_encounters      0.029\n",
       " 80  disengagement      disengagement      0.782\n",
       " \n",
       " [81 rows x 3 columns]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_folder = 'NoME&D'\n",
    "# in_folder=join(root_folder,\n",
    "#                final_folder,\n",
    "#               )\n",
    "in_folder = root_folder # join(root_folder, 'Data')\n",
    "csv_files = [join(root, name)\n",
    "             for root, dirs, files in walk(in_folder)\n",
    "             for name in files\n",
    "             if name.endswith('.csv')\n",
    "             # if 'NP20250204' in name # This are the extended\n",
    "             if 'mlvar_' in name # This are the limited\n",
    "             # if 'luster' not in name\n",
    "             # if 'participantsstatistics' not in name\n",
    "            ]\n",
    "# del(csv_files[-2])\n",
    "len(csv_files), csv_files\n",
    "\n",
    "mlvar_dict = {}\n",
    "for csv_file in csv_files[:]:\n",
    "    df = pd.read_csv(csv_file, \n",
    "                     # parse_dates=[2],\n",
    "                     # sep=' ',\n",
    "                     # skiprows=8,\n",
    "                     # header=None,\n",
    "                    )\n",
    "    key = (csv_file[:-4]\n",
    "           .split('\\\\')[-1]\n",
    "           .split('_')[1]\n",
    "          )\n",
    "    # columns = [c\n",
    "    #            for c in df.columns\n",
    "    #            if not c.startswith('Unnamed:')\n",
    "    #            # and not 'P' in c\n",
    "    #           ][:]\n",
    "    # df_mlvar = pd.DataFrame(columns=columns)\n",
    "    # for i, row in df.iterrows():\n",
    "    #     # print(key, row.dropna().values)\n",
    "    #     # pd.DataFrame(row)#.dropna()\n",
    "    #     # row.dropna()\n",
    "    #     df_mlvar.loc[i, :] = row.dropna().values\n",
    "    mlvar_dict[key] = df#_mlvar\n",
    "\n",
    "dict_mlvar = {}\n",
    "new_columns = ['n0',\n",
    "               'n1',\n",
    "               'similarity',\n",
    "              ]\n",
    "for key, df in mlvar_dict.items():\n",
    "    columns = df.columns\n",
    "    new_df = pd.DataFrame(columns=new_columns,\n",
    "                         )\n",
    "    if columns[0]=='v1':\n",
    "        # df0 = df.iloc[:, :3]\n",
    "        # df0.columns = new_columns\n",
    "        # df1 = df.iloc[:, 3:].values\n",
    "        # df1 = pd.DataFrame(columns=new_columns[-1:],\n",
    "        #                    data=df1,\n",
    "        #                   )\n",
    "        # for column, index in zip(new_columns[:-1],\n",
    "        #                          [1,0],\n",
    "        #                         ):\n",
    "        #     df1.insert(loc=0,\n",
    "        #                column=column,\n",
    "        #                value=(df0\n",
    "        #                       .iloc[:,index]\n",
    "        #                       .values\n",
    "        #                      ),\n",
    "        #               )\n",
    "        # new_df = pd.concat([new_df,\n",
    "        #                     df0,\n",
    "        #                     df1,\n",
    "        #                    ],\n",
    "        #                    axis=0\n",
    "        #                   )\n",
    "        new_df = pd.DataFrame(columns=new_columns,\n",
    "                              data=(df\n",
    "                                    .iloc[:,[0,1,4]]\n",
    "                                    .values\n",
    "                                   ),\n",
    "                             )\n",
    "    else:\n",
    "        # df.drop(df.columns[2],\n",
    "        #         axis=1,\n",
    "        #         inplace=True,\n",
    "        #        )\n",
    "        new_df = pd.DataFrame(columns=new_columns,\n",
    "                              data=(df\n",
    "                                    .iloc[:,[0,1,3]]\n",
    "                                    .values\n",
    "                                   ),\n",
    "                             )\n",
    "    dict_mlvar[key] = new_df\n",
    "\n",
    "dict_mlvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce838edb-2111-4b35-a892-7ce94ab0ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphBuilding(nodes, \n",
    "                  edges,\n",
    "                  directional=False,\n",
    "                 ):\n",
    "    if not directional:\n",
    "        g = nx.Graph()\n",
    "    else:\n",
    "        g = nx.DiGraph()\n",
    "    g.add_nodes_from(node for node in nodes.items())\n",
    "    g.add_edges_from([(c0, \n",
    "                       c1,\n",
    "                       # {'similarity': d['similarity'],\n",
    "                       #  'distance': d['distance'],\n",
    "                       # }\n",
    "                       d,\n",
    "                      )\n",
    "                      for (c0, c1), d \n",
    "                      in edges.items()\n",
    "                     ],\n",
    "                    )\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89ca8357-81c6-4a10-90ff-dea4d997b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StrengthCentrality(G, node, attribute):\n",
    "    \"\"\"\n",
    "    Node strength is defined as the sum of the strengths (or weights) of all\n",
    "    of the nodes edges.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G: graph\n",
    "       A networkx graph\n",
    "    node: object\n",
    "       A node in the networkx graph\n",
    "    attribute: object\n",
    "       The edge attribute used to quantify node strength\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    node strength: (int, float)\n",
    "    \"\"\"\n",
    "    output = 0.0\n",
    "    for edge in G.edges(node):\n",
    "        output += np.abs(G.get_edge_data(*edge)[attribute])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "486279a2-2f26-4762-bd78-5d92f1e0997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'between': <networkx.classes.graph.Graph at 0x28bd1bd9a30>,\n",
       " 'contemporaneous': <networkx.classes.graph.Graph at 0x28bd1bef8a0>,\n",
       " 'temporal': <networkx.classes.digraph.DiGraph at 0x28bd1b9ee90>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# direction = 'Symmetric'\n",
    "seed=13\n",
    "# (constructs_combinations,\n",
    "# constructs) = ConstructCombinations(df_long)\n",
    "# out_folder = r'.\\NetworksPlots\\mlVAR'\n",
    "# data_folder= r'.\\Results\\mlVAR'\n",
    "# plot_folder = 'Plots'\n",
    "# data_folder = 'Data'\n",
    "dict_graphs = {}\n",
    "for key, df_mlvar in dict_mlvar.items():\n",
    "    # constructs = list(df_mlvar['from'].value_counts().keys())\n",
    "    constructs = sorted(df_mlvar\n",
    "                  .iloc[:,:2]\n",
    "                  .stack()\n",
    "                  .value_counts()\n",
    "                  .keys()\n",
    "                 )\n",
    "    # constructs\n",
    "    constructs_combinations = df_mlvar.values\n",
    "    # constructs_combinations\n",
    "\n",
    "    edges = {(c0,c1):float(v) for c0,c1, v in constructs_combinations}\n",
    "\n",
    "    nodes = {q:{#'color':spectrum(i/len(constructs)),\n",
    "                      }\n",
    "             for i, q \n",
    "             in enumerate(constructs)\n",
    "            }\n",
    "\n",
    "    display_plot = True\n",
    "    # seed = 13\n",
    "    fontsize_node = 9.5\n",
    "\n",
    "    max_distance = max([d for d in edges.values()])\n",
    "\n",
    "    edges = {k:{'similarity':v,\n",
    "                # 'distance':1/v if,\n",
    "                'absolute_similarity': abs(v),\n",
    "               }\n",
    "             for k,v\n",
    "             in edges.items()\n",
    "            }\n",
    "    directional = True if key=='temporal' else False\n",
    "    g = GraphBuilding(nodes,\n",
    "                      edges,\n",
    "                      directional=directional,\n",
    "                     )\n",
    "\n",
    "    betweenness = nx.betweenness_centrality(g,\n",
    "                                            endpoints=True,\n",
    "                                            weight='absolute_similarity',\n",
    "                                           )\n",
    "    # degree = nx.degree_centrality(g)\n",
    "    closeness = nx.closeness_centrality(g,\n",
    "                                        distance='absolute_similarity',\n",
    "                                        wf_improved=True,\n",
    "                                       )\n",
    "    # eigenvector = nx.eigenvector_centrality(g,\n",
    "    #                                         weight='distance',\n",
    "    #                                         max_iter=1000,\n",
    "    #                                        )\n",
    "\n",
    "    strength = {node:StrengthCentrality(g,\n",
    "                                        node,\n",
    "                                        'absolute_similarity',\n",
    "                                       )\n",
    "                for node\n",
    "                in g.nodes()\n",
    "               }\n",
    "    # print(nodes.keys())\n",
    "    # fig, ax = GraphPlot(node_size_by=strength,\n",
    "    #                     g=g,\n",
    "    #                     plot_text=('Node size ~ Strength Centrality'\n",
    "    #                                '\\nEdges thickness ~ normalised fixed effects'\n",
    "    #                                '\\nEdge values = fixed effects'\n",
    "    #                               ),\n",
    "    #                     plot_title=('mlVAR Network\\n'\n",
    "    #                                 # 'mlVAR Network'\n",
    "    #                                 # 'Weighted average from all participants '\n",
    "    #                                 f'{key}'\n",
    "    #                                ),\n",
    "    #                     directional=directional,\n",
    "    #                    )\n",
    "\n",
    "    # color = dict(g.nodes.data('color'))\n",
    "    nodes_centralities = {n:{name:c[n] \n",
    "                             for name, c\n",
    "                             in [['betweenness', betweenness],\n",
    "                                 ['strength', strength],\n",
    "                                 # ['degree', degree],\n",
    "                                 ['closeness', closeness],\n",
    "                                 # ['color', color],\n",
    "                                ]\n",
    "                            } for n \n",
    "                          in nodes.keys()\n",
    "                         }\n",
    "    g = GraphBuilding(nodes_centralities,\n",
    "                      edges,\n",
    "                      directional=(True if key=='temporal' \n",
    "                                  else False),\n",
    "                     )\n",
    "    dict_graphs[key] = g\n",
    "    # with open(join(root_folder,\n",
    "    #                # data_folder,\n",
    "    #                f'mlVAR_{key}_NetGraph.pkl',\n",
    "    #               ),\n",
    "    #           'wb',\n",
    "    #          ) as f:\n",
    "    #     joblib.dump(g, f)\n",
    "\n",
    "    # for ext in ('png', 'pdf'): \n",
    "    #     out_path = join(root_folder,\n",
    "    #                     plot_folder,\n",
    "    #                     f'mlVAR_{key}_Py.{ext}',\n",
    "    #                    )\n",
    "    #     # out_path = join(out_folder, f'mlVAR_{key}_Py.{ext}')\n",
    "    #     plt.savefig(out_path,\n",
    "    #                 bbox_inches='tight',\n",
    "    #                )\n",
    "dict_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d641679-f6f4-4d41-bf47-e736caa25812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
